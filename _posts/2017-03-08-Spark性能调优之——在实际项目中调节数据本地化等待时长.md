---
layout: post
title: spark性能调优-数据本地化等待时长
date: 2017-03-08
categories: blog
tags: [spark调优]
description: spark调优
---

## 一、进程本地化级别

	1.PROCESS_LOCAL：进程本地化，
	
代码和数据在同一个进程中，也就是在同一个executor中；计算数据的task由executor执行，数据在executor的BlockManager中；**性能最好.**
 
	2.NODE_LOCAL：节点本地化

代码和数据在同一个节点中；比如说，数据作为一个HDFS block块，就在节点上，而task在节点上某个executor中运行；或者是，数据和task在一个节点上的不同executor中；数据需要在进程间进行传输

	3.NO_PREF

对于task来说，数据从哪里获取都一样，没有好坏之分

	4.RACK_LOCAL：机架本地化

数据和task在一个机架的两个节点上；数据需要通过网络在节点之间进行传输

	5.ANY

数据和task可能在集群中的任何地方，而且不在一个机架中，性能最差


## 二、数据本地化等待时长
spark.locality.wait，默认是3s

降级！！！！！！！ 次一点的还不行，再等待3秒。
再降级！！！等待。最后不行，就用最坏的！！！！


## 二、何时需要调节

怎么调？

看运行日志！
看WebUI

我们什么时候要调节这个参数？怎么调节！

观察日志，spark作业的运行日志，推荐大家在测试的时候，先用client模式，在本地就直接可以看到比较全的日志。
日志里面会显示，starting task。。。，PROCESS LOCAL、NODE LOCAL

观察大部分task的数据本地化级别
如果大多都是PROCESS_LOCAL，那就不用调节了

如果是发现，好多的级别都是NODE_LOCAL、ANY，那么最好就去调节一下数据本地化的等待时长。


调节完，应该是要反复调节，每次调节完以后，再来运行，观察日志
看看大部分的task的本地化级别有没有提升；看看，整个spark作业的运行时间有没有缩短。

### 注意

别**本末倒置**，本地化级别倒是提升了，
但是因为大量的等待时长，spark作业的运行时间反而增加了，那就还是不要调节了。

##  三、怎么调节？
spark.locality.wait，默认是3s；6s，10s

默认情况下，下面3个的等待时长，都是跟上面那个是一样的，都是3s

spark.locality.wait.process
spark.locality.wait.node
spark.locality.wait.rack

new SparkConf()
.set("spark.locality.wait", "10")






## 四、原理浅析


Spark在Driver上，对Application的每一个stage的task进行分配之前，都会计算出每个task要计算的是哪个分片数据，RDD的某个partion；
Spark的task分配算法，优先。会希望每个task正好分配到它要计算的数据所在的节点，这样的话，就不用在网络上传输数据。

有时，事与愿违，task没有机会正好分配到数据所在的节点。

为什么呢？ 可能那个节点的计算资源和计算能力都满了。
通常会等待一段时间，默认3s。（不是绝对的，还有很多种情况，）

默认情况下是3s钟（不是绝对的，还有很多种情况，对不同的本地化级别，都会去等待），到最后，实在是等待不了了，就会选择一个比较差的本地化级别，

比如说，将task分配到靠它要计算的数据所在节点，比较近的一个节点，然后进行计算。

但是对于第二种情况，通常来说，肯定是要发生数据传输，task会通过其所在节点的BlockManager来获取数据，

BlockManager发现自己本地没有数据，会通过一个getRemote()方法，

通过TransferService（网络数据传输组件）从数据所在节点的BlockManager中，获取数据，通过网络传输回task所在节点。

对于我们来说，当然不希望是类似于第二种情况的了。

最好的，当然是task和数据在一个节点上，直接从本地executor的BlockManager中获取数据，纯内存，或者带一点磁盘IO；

如果要通过网络传输数据的话，那么实在是，性能肯定会下降的，大量网络传输，以及磁盘IO，都是性能的杀手。


	
