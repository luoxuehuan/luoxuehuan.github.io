### 个人资料

- 姓        名： 罗学焕
- 籍        贯： 浙江衢州    
- 政治面貌： 共产党员
- 电子邮箱： 18868825313@163.com 
- 学        历： 本科                   
- 出生年月： 1993-10
- 毕业院校： 杭州电子科技大学
- 联系电话： 188-6882-5313

### 自我评价

熟练掌握Java语言。熟悉JVM原理，熟悉Scala语言。

熟练掌握Spark并熟悉其原理源码。对大数据生态：离线处理（Hadoop、Hive、Presto）和实时处理（Spark Steaming、Flink、Kafka）都有应用、原理、架构上的认知。

熟练使用Spring、Mybatis、Dubbo等Java框架。

兼具大数据开发经验及大数据平台整合经验。对大数据平台产品设计和产品优化有一定经验。

热爱钻研，能自驱学习，寻求挑战，善于解决问题，对技术具有浓厚的兴趣。 

会在公司做技术分享，并参与线下技术交流会议，关注新技术发展和动态，会写自己的博客对知识进行记录总结。

### 项目经历

> 滴滴出行   研发中心-平台研发  资深研发工程师     主要工作：数据地图研发、大数据项目开发、项目管理、项目支持、POC、技术调研、问题解决    2021.03 – 2021.03

Ø  **数据探查**                                              

**时间：** 2021.2– 2022.03

**项目简介：** 数栖探查系统支持对hive、mysql等表、json、csv文件等数据， 进行数据探查。探查包括基础探查、高级探查。

**负责要点：**

1. 探查系统架构设计。
2. 探查接口开发。
3. 探查任务开发。
4. 探查执行对接。

** **

Ø  **数据地图**                                              

**时间：** 2021.3– 2022.01

**项目简介：** 数栖地图是滴滴出行负责数据搜索与管理的大数据产品。支持Hive表、MySQL、实时表、报表等搜索、支持血缘能力，变更通知、专辑管理能力。

**所用技术：**  Spark、Spring Boot等。

**产品地址**：<https://www.dtwave.com/shuqi>

**负责要点：**

1. 数据专辑模块研发
2. 数据血缘能力建设。
3. 多环境集群部署。
4. 数据搜索能力建设。 
5. 问题解决。


** **

> 杭州数澜科技有限公司   研发中心-平台研发  大数据平台研发工程师     主要工作：数栖平台产品开发,大数据项目开发,项目支持,技术调研,问题解决    2016.11 – 至今

Ø  **数栖平台**                                              

**时间：** 2017.4– 2020.09

**项目简介：** 数栖平台是本公司最核心的一款大数据产品。集成离线数据开发、实时数据开发、数据资产管理、数据同步、数据应用等于一体的大数据开发套件。

**所用技术：**  Spark、Flink、Hadoop、Hive、Kafka、Presto、Dubbo、Spring Boot、Mybatis、Antlr、CarbonData、ClickHouse等。

**产品地址**：<https://www.dtwave.com/shuqi>

**负责要点：**

1. 平台早期版本任务编辑、实例化模块、调度模块、执行模块、引擎管理等各个模块**核心开发**。（后期迭代版本有新的功能迭代、清楚技术设计、但未全程参与开发）
2. 离线任务：封装并支持Spark、SparkSQL、PySpark、Hive2、GP等计算任务、提供查询结果下载，日志查询等功能。开发基于Spark DataSource的数据同步任务。
3. 平台早期版本实时任务：

   1. 协助可选Flink执行引擎开发、Source支持Kafka （Json结构，自定义schema）、Sink支持ES、MySQL等sink。
   2. 负责可选 Spark Structured Streaming执行引擎开发,基于Kafka元数据管理，自解析Schema。支持SQL Transform Pipeline。
   3. 负责自研Antlr SQL解析语法、解析输入转换输出、支持实时任务以全SQL方式开发。
4. 数据管理子系统：负责基于Hive元数据自研库、表、字段管理、基于Spark进行生命周期、血缘管理开发。
5. 数据质量子系统：负责库、表、字段级别质量检测、质量阻塞功能开发。
6. 数据安全子系统：负责自研基于Hive Driver解析和Spark Logical Plan优化层解析的用户及项目空间的库、表、字段、函数级别权限管理系统。可进行SQL表级血缘和字段级别血缘的解析。
7. 平台技术预研（2019.12）：Alluxio增强Presto查询功能，ClickHouse SQL性能对比分析等。
8. 集群Yarn、Spark参数调优、HDFS扩容升级、线上问题Trouble Shooting、帮助使用平台的数据同学进行Performance Turning、Spark、Hadoop、Hive、Flink等的内核原理源码研究。


**总结：** 从0到1、从1到100，完整的跟随数栖平台走过，对一整个数据中台有自己较为完善的理解。

** **

Ø  **数栖平台-数据资产-数据质量系统、数据地图系统**                                              

**时间：** 2020.1– 2020.11

**项目简介：** 1.数据质量系统是对数栖原有数据质量系统进行的一个单独拆分和增强改造，由原有的每日凌晨任务跑完后的定时任务进行数据规则计算，改造为根据调度任务解析血缘产出表，进行实时的质量规则计算，可达到一个阻塞下游任务的效果。

2.数据地图系统是集数据采集、元数据管理、元模型管理、数据血缘关系展示、元数据查询、数据搜索功能的数据治理系统中的一个子系统。

**所用技术：** Spark、SparkSQL、Hive、Spring Boot、MybatisPlus、ElasticSearch等。

**负责要点：**

1. 作为项目负责人，带领1名后端开发、1名前端、进行系统开发。在数栖5.0大版本结束时获得全能个人奖表彰。
2. 负责项目项目进度与工作评估，技术方案设计，流程设计，数据库设计。
3. 负责迭代一核心Spark数据质量任务内容的开发，质量任务可依赖调度模块实现表级、字段级各个规则的实时校验并产出校验结果。根据规则本身强弱，实现阻塞下游任务运行的效果。
4. 负责和数栖调度中心对接，表-质量任务提交，关联调度等的开发。
5. 负责迭代二质量分析，质量报告，知识库等后端业务功能开发。
6. 使用Logstash将MySQL中元数据同步到ElasticSeach,基于ElasticSearch进行搜索功能开发。

**总结：** 沉淀了数据治理、数据质量业务、数据元模型等的业务认知。

** **

Ø  **SX银行实时计算定制化开发-Flink实时计算项目**                                            

**时间：** 2018.12– 2019.7

**项目简介：** 使用Flink实时计算框架对银行内核心结算系统、网银、二代等支付系统做账户余额计算和交易对手补全，并将结果写入到ElasticSearch供下游各个系统查询。

**所用技术：** Flink、ElasticSearch、Kafka、WebService、Apache Cxf等。

**负责要点：**

1. 作为技术负责人，带领2名数据开发1名后端Java开发，推进项目完成。
2. 负责项目项目进度与工作评估，架构设计，流程设计，数据库设计。
3. 前期的Flink技术预研与后期的核心开发：流的切分，Oracle Ogg数据格式的解析，Kafka流与Hbase维表或Oracle维表的Join，维表缓存的使用。规划与集成新的Flink核心技术至自研数栖平台。
4. 银行账户余额与应用热更新等的方案设计。JVM内存溢出问题解决，RocksDB方案验证与使用。
5. 业务梳理、解决数据开发同学遇到的问题。
6. 服务查询应用WebService服务、历史数据与实时数据查询方案设计、对接ESB开发。
7. 给SX银行开发和运维人员做培训。

**总结：** 开始独立负责项目、对项目把控、推进、风险处理有了更深的理解。

** **

Ø  **广州一呼百应用户行为分析大屏**                       

**时间：** 2017.7– 2017.9

**项目简介**：一呼百应电商用户行为分析是根据在前端埋点收集用户操作日志，经Flume传输到Kafka和Hive进行离线分析和实时分析的综合系统。

**所用技术**：Flume，Spark SQL，Spring Boot、Flink、阿里DataV

**负责要点**：

1. 基于Flink对Kafka中原始日志实时解析生成Json结构存入Kafka。
2. 二次排序。内外外网跳入TopN统计。
3. PV、UV计算，注册计算，来源统计，分类PV、UV、计算注册率以及跳出率、神通金消耗计算等。
4. 使用Spark SQL 、UDF函数以及开窗函数统计计算热门类目。
5. 从Hive表抽取Session数据并处理，将结果存入MySQL数据库，供DavaV调用展示。
6. Flink SQL对Kafka Json数据实时计算。利用窗口函数 及SQL ,实时计算PV存入MySQL。
7. 算子调优，Shuffle调优，JVM调优数据倾斜解决，trouble shooting等。

** **

Ø  **哒哒招标** ——基于招投标信息的推荐分析系统                 

**时间：** 2016.12– 2017.4

**项目简介:** 哒哒招标是基于互联网招投标数据而研发的分析的产品，基于爬虫获取网上最新的爬虫数据，并通过解析，分析，进行分析，发掘隐藏在数据深层的价值。

**所用技术:** Java，Scala,Hive，阿里Odps,Spark,ElasticSearch，Spring Boot 

**负责要点:**

1. 爬虫：使用分布式爬虫爬取全网招投标信息。
2. 基于结构化解析后的数据做数据开发与分析。
3. 基于ElasticSearch搜索查询聚合功能 ：
4. 搜索招投标信息、公司信息
5. 对中标或招标公司做实时画像分析（历史中标分布、中标行业分布、中标金额分布）
6. 某项招标信息的竞标对手预测。

** **

Ø  **社保通**  ——大数据疾病预测判断系统                          

**时间：** 2016.11– 2017.3

**项目简介:**哒哒招标是基于互联网招投标数据而研发的分析的产品，基于爬虫获取网上最新的爬虫数据，并通过解析，分析，进行分析，发掘隐藏在数据深层的价值。

**所用技术:** Python、Shell、Spark

**负责要点:**

1. 基于社保大数据、药品与疾病基础数据 进行数据开发与分析得出疾病预测模型达疾病预测 概率判断 的效果。
2. 针对医疗保险核保场景，创新设计推出大数据服务解决方案，帮助保险公司精准识别真正有需求的客户，进而大幅降低核保风险。产品功能包括：疾病查验、智能保单、疾病预测。


** **

> 国电南京自动化股份有限公司   信息技术事业部      Java开发工程师          主要工作:产品开发 2015.3– 2016.9

Ø  **数据工厂**                                    

**时间：** 2016.4 – 2016.7

**项目简介:** 数据工厂项目是一款面向发电集团的互联网产品，依托于国电南自10年来在发电企业的数据积累，针对日常生产经营数据信息需求，通过大数据分析技术，服务于各级管理者，发掘隐藏在数据深层的价值。

**所用技术:** Zookeeper，Hadoop，Hbase，Spring，Spring MVC，Restful，MQ，WebService，Redis。

**负责要点:**

1. 后台接口开发，调用MQ以及WebService服务从集团的燃料电厂营销环保机组等系统中抽取数据出来。
2. 将抽取到的数据存在Hbase以及关系型数据库。
3. 编写MapReduce程序和Java程序进行全集团内电厂多维度统计，趋势，排名，对标分析，根据计算模型进行盈利情况预测，并将结果存在数据库和缓存，供移动端快速调取进行数据可视化展示。

** **

Ø  **teaM**                                         

**时间：** 2015.7 - 2016.8

**项目简介:** teaM是一个面向互联网团队管理的软件产品，融入了计划管理，进度管理，任务管理与提醒，周报日报功能，旨在为项目管理提供更多的便捷。

**所用技术:** Spring，Spring MVC，Hibernate，Eclipse，Memcached，Oracle等。

**负责要点:**

1. 采用线程池提高邮件发送效率,Shiro权限验证。
2. AOP个人动态记录，Restful服务，MD5数据加密存储。
3. 使用Memcached缓存优化数据加载速度。
4. 弃用平台提供的定时任务管理采用Spring注解更为便捷地开发定时任务等。
