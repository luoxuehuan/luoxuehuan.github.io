## 使用案例 机器学习
- 1.商品特征未读降维 ：SVD 、PCA
- 2.商品挂错页面检查：TF-IDF、SVM、Logistic - -Regression
- 3.相关推荐算法模型训练：Loginistic Regression、kmeans、SVM
- 4.商品爆品预测 ：Loginistic Regression
- 5.关联性分析：FPGrowth
- 6.开发了基于Mllib的机器学习平台

## 经验分享
### 用户常见错误
1.
问题：Collect 大量数据到Driver端，导致driver oom；算法开发的时候没有注意

解决：driver不能堆积大量数据，尽量不要在driver保存数据

2.
问题：维表数据没用cache内存或者repartition数目太多
解决：将维表数据cache到内存，分区数目不能太多

3.
问题：未对Spark的持久化级别进行选择，需要根据实际的业务需求进行选择
解决：统计RDD的数据量，大数据量将Memory_AND_DISK作为首选

4.
问题：读写DB没有设置合理的分区数目，并发量太高，影响业务
解决：统计DB的表分区结构，监控DB服务load，压测到位

5.
问题 ：Spark使用Hbase scan性能不稳定
解决：Get性能相对稳定，尽量使用Get

6.
问题：History server 重启需要回放180G日志，需要4个小时，新完成的app在History server无法立即看到
解决： 改为多线程会放 SPARK-13988

7.
问题 经常回出现class not found ，但是class文件再包里面存在
解决办法 打印classloadder分析，建议不要轻易修改源码classloader

8.
PCA算法只能支持小于14W feature特性
解决办法 使用SVD进行降维

9.
问题 FPGrowth不支持 KryoSerializer
解决办法 1.6.2 之前使用java Serializer

10.
Spark在使用JDBC接口建立DataFrame时，需通过执行SQL来获取该JDBC数据源的Schema，导致创建大量的DataFrame的时候非常耗时

解决办法：Schema相同的table可以不用重复获取schema
地址：https://github.com/ouyangshourui/SparkJDBCSchema/wiki
4000个DataFrame的初始化时间从原先的25分钟缩短为10分钟以内



### Spark平台权限

1.4.0 Standalone cluster模式不支持多用户
相关组件读写权限问题无法解决，比如读取Hive、Hbase、HDFS数据的权限问题
解决办法：修改SparkContext sparkuser 和system username
代码地址：https://github.com/ouyangshourui/ouyangshourui/StandalongClusterAuthorization/wiki


Spark Sql Hive元数据密码加密，javax.jdo.option.ConnectionPassword暴露给用户比较危险
解决办法：修改HiveContext.scala文件中的metadataHive变量，选择自定义的解密算法解密
代码地址： https://github.com/ouyangshourui/HivePasswordEncryptionDecryption/wiki

Spark1.5.2 Sql放大了Hive读权限，任何用户都可以读取别的用户的Hive表数据
临时解决办法，生成HiveTableScan operator时调用driver已有的Hive Client 权限接口检查当前用户的读权限

https://github.com/ouyangshourui/HiveReadpermission/wiki


### 升级遇到的问题


1.4.0 Standalone 升级到1.5.2 on Yarn

用户代码使用system.exit(-1) RM web UI却显示正常，建议直接hrow exception

- 自定义封装MySQL PostgreSql JDBC 没有考虑driver JDBC Dialect的实现导致数据无法返回。

- 每个Executor都与Hive简历connection去获取HiveConf 没有broadcast HiveConf（SPARK -10679）

多版本Spark Dynamic Persource Allocation无法共存，DRA需重启Yarn NodeManger ，耦合性太强（没有解决）

### TODO
Spark Streaming 全面落地，吸收Apache Bean思想
Spark Sql替代大部分Hive任务
SPark现有任务优化加速
完善机器学习平台 覆盖大部分电商和金融领域机器学习算法库

全面拥抱Spark2.0 参与社区
